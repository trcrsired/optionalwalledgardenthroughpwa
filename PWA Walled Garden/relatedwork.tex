\section{Related Work}

\textit{Dynamic Malware Analysis in the Modern Era--A State of the Art Survey}\cite{10.1145/3329786}, authored by Or-Meir, Ori, Nissim, Nir, Elovici, Yuval, and Rokach, Lior, provides a definition of malware and categorizes it into various types, including viruses, trojans, spyware, worms, adware, scareware, bots, ransomware, and cryptominers. The paper also classifies malicious behaviors associated with malware. It offers a comprehensive survey evaluating the strengths and weaknesses of different analysis methods and their resilience against malware evasion techniques. In addition, the authors highlight how mainstream approaches predominantly rely on machine learning for malware detection.
The paper \textit{Analysis of Machine learning Techniques Used in Behavior-Based Malware Detection} by Firdausi, Ivan, Lim, Charles, Erwin, Alva, and Nugroho, Anto Satriyo employed the J48 decision tree algorithm, achieving a recall of 95.9\%, a false positive rate of 2.4\%, a precision of 97.3\%, and an accuracy of 96.8\%. \textit{Malware Classification with Recurrent Networks}\cite{7178304} by Pascanu, Razvan, Stokes, Jack W., Sanossian, Hermineh, Marinescu, Mady and Thomas, Anil explored malware detection using a recurrent bidirectional neural network to analyze system calls, with their best model yielding a precision of 82\% and a false positive rate of 0.5\% based on 114 distinct system calls from 250,000 malware samples. \textit{A Machine-Learning Approach for Classifying and Categorizing Android Sources and Sinks}\cite{rasthofer2014machine} by Rasthofer, Siegfried, Arzt, Steven, and Bodden, Eric proposed the SUSI framework, evaluated on 11,000 malware samples, with their top-performing model achieving an accuracy of 92.3\%. \textit{Adaptive Detection of Covert Communication in HTTP Requests}\cite{6377758} by Schwenk, Guido and Rieck, Konrad analyzed 695 malware samples but did not report metrics such as accuracy, precision, or false positive rate. \textit{Trusted System-Calls Analysis Methodology Aimed at Detection of Compromised Virtual Machines Using Sequential Mining}\cite{10.1016/j.knosys.2018.04.033} by Nissim, Nir, Lapidot, Yuval, Cohen, Aviad and Elovici, Yuval utilized memory dumps from virtual machines and reconstructed systems using WinDbg; their analysis of ten malware and six benign samples with random forest achieved a precision rate of 98\% with no false positives. \textit{Machine Learning in Side-Channel Analysis: A First Study}\cite{hospodar2011machine} by Hospodar, Gabriel, Gierlichs, Benedikt, De Mulder, Elke, Verbauwhede, Ingrid and Vandewalle, Joos demonstrated that machine learning could effectively extract cryptographic keys using power consumption traces as features, with their LS-SVM linear classifier reaching a success rate of 75\%. \textit{On the Feasibility of Online Malware Detection with Performance Counters}\cite{10.1145/2508148.2485970} by Demme, John, Maycock, Matthew, Schmitz, Jared, Tang, Adrian, Waksman, Adam, Sethumadhavan, Simha, and Stolfo, Salvatore tested their decision tree-based implementation on Android and Linux, using 201 benign samples and 503 malware samples, achieving a detection rate of 83\% and a false positive rate of 10\%. Finally, \textit{EDDIE: EM-Based Detection of Deviations in Program Execution}\cite{10.1145/3079856.3080223} by Nazari, Alireza, Sehatbakhsh, Nader, Alam, Monjur, Zajic, Alenka and Prvulovic, Milos monitored electromagnetic emissions from embedded and IoT devices, detecting statistical anomalies caused by code injections into application loops.

\textit{Understanding and Detecting Real-World Safety Issues in Rust}\cite{10.1145/3385412.3386036} by Qin, Boqin, Chen, Yilun, Liu, Haopeng, Zhang, Hua, Wen, Qiaoyan, Song, Linhai, and Zhang, Yiying highlights that programming languages like Rust can encounter memory safety issues if the \texttt{unsafe} keyword is misused. The authors conducted an extensive study, analyzing five widely-used Rust libraries and two online security databases. Their manual inspection uncovered 70 memory bugs, 100 concurrency bugs, and 110 programming errors leading to panics. This research emphasizes that excessive reliance on \texttt{unsafe} significantly diminishes its intended effectiveness.

\textit{Is Google Getting Worse? A Longitudinal Investigation of SEO Spam in Search Engines}\cite{10.1007/978-3-031-56063-7_4} by Bevendorff, Janek, Wiegmann, Matti, Potthast, Martin, and Stein, Benno examines the decline in Google Search quality due to the rise of SEO spam. The study highlights how spam and link farms are becoming increasingly indistinguishable, a trend that is expected to worsen with the advent of generative AI.

\textit{Bringing the Web Up to Speed with WebAssembly}\cite{10.1145/3062341.3062363} by Barzolevskaia, Anna, Branca, Enrico, and Stakhanova, Natalia serves as a foundational work introducing WebAssembly by detailing its motivation, design, and formal semantics. \textit{Not so Fast: Analyzing the Performance of WebAssembly vs. Native Code} by Jangda, Abhinav, Powers, Bobby, Berger, Emery D., and Guha, Arjun developed BROWSIX-WASM to evaluate the performance gap between WebAssembly and native code, finding an average slowdown of 45\% on Firefox and 55\% on Chromium, with peak slowdowns of 2.08x (Firefox) and 2.5x (Chrome). The performance issues were attributed to both platform-specific factors, such as bounds checking and function call verification, and missing optimizations. \textit{Everything Old is New Again: Binary Security of WebAssembly}\cite{255318} highlights how WebAssembly binaries, often compiled from memory-unsafe languages like C/C++, remain vulnerable to memory safety exploits, enabling the construction of malicious cross-site scripting attacks. \textit{WebAssembly Memory Tagging}\cite{webassemblymemorytagging} by Shengdun W. and Aravind P. offers a solution to WebAssembly's memory safety concerns using memory tagging, inspired by the ARM Memory Tagging Extension. Their research demonstrates that software-based memory tagging introduces overheads of 48.91\% for Wasm64 and 72.38\% for Wasm32, but with ARM MTE-supported CPUs, these overheads drop significantly to 5.71\% for Wasm64 and 18.05\% for Wasm32, while effectively addressing real-world CVEs.